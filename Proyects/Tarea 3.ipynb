{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyProje2EGork13aCmd8qY/d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##TAREA 3\n","_Jhojan Stiven Zea Fernandez_\n","\n","_CC 1037669632_\n"],"metadata":{"id":"SstaMh3QOjbN"}},{"cell_type":"markdown","source":["##PUNTO 1\n","\n","Encontrar el SVD (Singular value decomposition) de la matriz\n","\n","$$A=\\begin{pmatrix}\n","1 & 2 \\\\\n","0 & -1 \\\\\n","3 & -2\n","\\end{pmatrix}\n","$$\n","\n","_Solucion_\n","\n","Encontramos $A^{*}$, ya que todos los elementos de la matriz estan en $\\mathbb{R}$ entonces $A^{*}=A^{T}$\n","\n","$$A^{*}=\\begin{pmatrix}\n","1 & 0 & 3 \\\\\n","2 & -1 & -2\n","\\end{pmatrix}$$\n","\n","UUtilizando el codigo de abajo, encontramos $AA^{*}$\n","\n","$$AA^{*}=\\begin{pmatrix}\n","1 & 2 \\\\\n","0 & -1 \\\\\n","3 & -2\n","\\end{pmatrix}\n","\\begin{pmatrix}\n","1 & 0 & 3 \\\\\n","2 & -1 & -2\n","\\end{pmatrix}\n","=\\begin{pmatrix}\n","5 & -2 & -1 \\\\\n","-2 & 1 & 2 \\\\\n","-1 & 2 & 13\n","\\end{pmatrix}$$\n","\n","Usando el codigo de abajo, encontramos $A^{*}A$\n","\n","$$A^{*}A=\\begin{pmatrix}\n","1 & 0 & 3 \\\\\n","2 & -1 & -2\n","\\end{pmatrix}\n","\\begin{pmatrix}\n","1 & 2 \\\\\n","0 & -1 \\\\\n","3 & -2\n","\\end{pmatrix}\n","=\\begin{pmatrix}\n","10 & -4 \\\\\n","-4 & 9\n","\\end{pmatrix}$$\n","\n","\n","\n","\n","\n"],"metadata":{"id":"81Z68ATrPVAN"}},{"cell_type":"code","source":["import numpy as np\n","\n","A = np.array([[1, 2], [0, -1], [3, -2]])\n","A_adj = A.transpose()\n","A_adj_A = np.dot(A_adj, A)\n","A_A_adj = np.dot(A, A_adj);\n","print(\"AA*\")\n","print(A_A_adj)\n","print(\"A*A:\")\n","print(A_adj_A)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PNBTPT-TwxX","executionInfo":{"status":"ok","timestamp":1741380738765,"user_tz":300,"elapsed":6,"user":{"displayName":"Stiven Zea","userId":"11197082539523266029"}},"outputId":"282756a8-c85f-4f73-e246-3f005010e516"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["AA*\n","[[ 5 -2 -1]\n"," [-2  1  2]\n"," [-1  2 13]]\n","A*A:\n","[[10 -4]\n"," [-4  9]]\n"]}]},{"cell_type":"markdown","source":["Utilizando la definicion para el polinomio caracteristico de una matriz $p(\\lambda)=|A-λI|=0$ calculamos el polinomio caracteristico de la matriz $AA^{*}$\n","con ayuda de Gemini para no extender el proceso.\n","\n","$$p(\\lambda)=|AA^{*}-λI|= |\\begin{pmatrix}\n","5-\\lambda & -2 & -1 \\\\\n","-2 & 1-\\lambda &2 \\\\\n","-1 & 2 & 13-\\lambda\n","\\end{pmatrix}|=-\\lambda^{3}+19\\lambda^{2}-74\\lambda=0$$\n","\n","De manera obvia, se puede sacar el factor $\\lambda$ de cada termino, por lo cual tenemos ya un autovalor $\\lambda_{3}=0$, los otros dos se calculan utilizando la calculadora grafica desmos y se ordenan de mayor a menor.\n","$$\\lambda^1_1=13.53$$\n","$$\\lambda^1_2=5.47$$\n","$$\\lambda^1_3=0$$\n","\n","Siguiendo el mismo procedimiento para la matriz $A^{*}A$, podemos encontrar que su polimomio caracteristico es:\n","$$p(\\lambda)=|A^{*}A-λI|=\\lambda^{2}-19\\lambda+74$$\n","y sus autovalores, ordenados de mayor a menor son:\n","$$\\lambda^2_1=13.53$$\n","$$\\lambda^2_2=5.47$$\n","\n","Como se puede comprobar en el siguiente codigo"],"metadata":{"id":"geWy_jP1VnJU"}},{"cell_type":"code","source":["import numpy as np\n","\n","A = np.array([[1, 2], [0, -1], [3, -2]])\n","A_adj = A.transpose()\n","A_adj_A = np.dot(A_adj, A)\n","A_A_adj = np.dot(A, A_adj);\n","\n","\n","Valores_propios, Vectores_propios = np.linalg.eig(A_A_adj)\n","Valores_propios2, Vectores_propios2 = np.linalg.eig(A_adj_A)\n","print(\"Valores propios de AA*\")\n","print(Valores_propios)\n","print(\"Valores propios de A*A\")\n","print(Valores_propios2)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtgAoIlfaaAj","executionInfo":{"status":"ok","timestamp":1741386072892,"user_tz":300,"elapsed":24,"user":{"displayName":"Stiven Zea","userId":"11197082539523266029"}},"outputId":"a8f42eed-0348-4db0-fd00-911a73450079"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Valores propios de AA*\n","[ 0.          5.46887113 13.53112887]\n","Valores propios de A*A\n","[13.53112887  5.46887113]\n"]}]},{"cell_type":"markdown","source":["Los valores singulares se calculan como la raiz de los valores propios, por tanto\n","$$\\sigma_1=\\sqrt{13.53} ≈ 3.68$$\n","$$\\sigma_2=\\sqrt{5.47} ≈ 2.34$$\n","\n","Se calculan los autovectores unitarios de $AA^{*}$, los cuales son las columnas de la matriz $U$, con el codigo de python que se puede ver mas abajo, ya que python no entrega los autovectores necesariamente ordenados, se utiliza wolfram alpha para hacer la comprobacion de que autovalores le corresponden a cada vector con el fin de ordenarlos de mayor a menor.\n","\n","$$U_1=\\begin{pmatrix}\n","-0.16 \\\\\n","0.18\\\\\n","0.97\n","\\end{pmatrix}$$\n","\n","$$U_2=\\begin{pmatrix}\n","-0.92 \\\\\n","0.32 \\\\\n","0.21\n","\\end{pmatrix}$$\n","\n","$$U_3=\\begin{pmatrix}\n","-0.35 \\\\\n","-0.93 \\\\\n","0.12\n","\\end{pmatrix}$$\n","\n","Con el mismo codigo, se calculan los autovalores de $A^{*}A$, los cuales son las columnas de la matriz $V$\n","\n","$$V_1=\\begin{pmatrix}\n","0.75 \\\\\n","-0.66\n","\\end{pmatrix}$$\n","\n","$$V_2=\\begin{pmatrix}\n","0.66 \\\\\n","0.75\n","\\end{pmatrix}$$\n"],"metadata":{"id":"HiIhXEQejxkN"}},{"cell_type":"code","source":["import numpy as np\n","\n","A = np.array([[1, 2], [0, -1], [3, -2]])\n","A_adj = A.transpose()\n","A_adj_A = np.dot(A_adj, A)\n","A_A_adj = np.dot(A, A_adj);\n","\n","\n","Valores_propios, Vectores_propios = np.linalg.eig(A_A_adj)\n","Valores_propios2, Vectores_propios2 = np.linalg.eig(A_adj_A)\n","print(\"Vectores propios de AA*\")\n","print(Vectores_propios)\n","print(\"Vectores propios de A*A\")\n","print(Vectores_propios2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2xNo2nqwKHO","executionInfo":{"status":"ok","timestamp":1741387119700,"user_tz":300,"elapsed":14,"user":{"displayName":"Stiven Zea","userId":"11197082539523266029"}},"outputId":"9fbd2f37-3ad4-4c48-c322-d99c3a9d078b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Vectores propios de AA*\n","[[-0.34874292 -0.92414019 -0.15602335]\n"," [-0.92998111  0.32057232  0.17991254]\n"," [ 0.11624764 -0.20784199  0.97123025]]\n","Vectores propios de A*A\n","[[ 0.74967818  0.66180256]\n"," [-0.66180256  0.74967818]]\n"]}]},{"cell_type":"markdown","source":["Con todo lo anterior se construyen $U,V^{T}$ y $Σ$\n","\n","$$A=U \\Sigma V^{T}=\\begin{pmatrix}\n","0.16 &0.92&-0.35\\\\\n","-0.18 & -0.32 & -0.93\\\\\n","-0.97 & 0.21 & 0.12\n","\\end{pmatrix}\n","\\begin{pmatrix}\n","3.68 & 0 \\\\\n","0 & 2.34 \\\\\n","0 & 0\n","\\end{pmatrix}\n","\\begin{pmatrix}\n","-0.75 & 0.66\\\\\n","0.66 & 0.75\n","\\end{pmatrix}$$\n","\n","\n","Debido a las ambiguedades en la descomposicion SVD, y sabiendo que un vector propio por un escalar tambien es un vector propio de la matriz, se utilizó wolfram alpha para descifrar la correcta descomposicion de la Matriz, multiplicando por -1 los vectores $U_1, U_2, V_1$\n","\n","La descomposicion se puede comprobar con el siguiente codigo\n"],"metadata":{"id":"epz_MJcr17Gm"}},{"cell_type":"code","source":["import numpy as np\n","\n","U = np.array([[0.16, 0.92, -0.35],\n","              [-0.18, -0.32, -0.93],\n","              [-0.97, 0.21, 0.12]])\n","\n","E = np.array([[3.68, 0],\n","              [0, 2.34],\n","              [0, 0]])\n","\n","UE = np.dot(U, E)\n","\n","VT = np.array([[-0.75, 0.66],\n","              [0.66, 0.75]])\n","\n","UEVT = np.dot(UE, VT)\n","print(UEVT)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QbFcPBVi3jve","executionInfo":{"status":"ok","timestamp":1741390670128,"user_tz":300,"elapsed":9,"user":{"displayName":"Stiven Zea","userId":"11197082539523266029"}},"outputId":"121b31f2-9655-4be1-bcd9-83750dbc9d70"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 9.792480e-01  2.003208e+00]\n"," [ 2.592000e-03 -9.987840e-01]\n"," [ 3.001524e+00 -1.987386e+00]]\n"]}]},{"cell_type":"markdown","source":["Este calculo (debido a redondear los calculos a 2 decimales) es aproximadamente igual a la matriz $A$, por lo tanto se prueba que la descomposicion SVD de esta matriz fué realizada correctamente"],"metadata":{"id":"1UHUbyX8ACTR"}},{"cell_type":"markdown","source":["#Punto 2\n","\n","**Ambiguedad en el SVD**\n","\n","Hay una gran cantidad de ambiguedad en la decomposicion SVD. Considere la matriz identidad. En cuantas formas validas se puede escribir $I_n=U\\Sigma V^{T}$? Asuma que ya has decidido que vectores ortonormales columna $u_1, u_2, \\cdots , u_r$, de la matriz $U_r$, que corresponden a algunos valores singulares diferentes de cero de la matriz $A\\quad m\\times n$. Correspondientemente, van a haber $v_1,v_2,\\cdots,v_r$ vectores propopios ortonormales que son columnas de la matriz $V_r$. Se podrian cambiar los signos de esos vectores, resultando en $2^{r}$ posibilidades para escoger los autovectores ortonormales $v_i$ y solo una de esas combinaciones dá la factorizacion SVD correcta. Como se escoge la matriz $V_r$ Correcta?, por favor comentar sobre los autovectores que corresponden a autovalores de cero.\n","\n","_Solucion_\n","\n","De la definicion de descomposicion SVD vista en clase $U$ es una matriz ortogonal de tamaño $m\\times m$, $Σ$ es una matriz diagonal $m\\times n$ que contiene todos los valores singulares de la matriz original en su diagonal, y $V^{T}$ es la transpuesta de una matriz ortogonal $n\\times n$\n","\n","Considerando la Matriz identidad, al multiplicarla por cualquier matriz o Vector, esta no produce ninguna transformación, por lo que se puede decir que los valores propios de una matriz $I_n$ van a ser $\\lambda_n=1$, debido a esto, la matriz $Σ=I_n$, con esto, la descomposicion SVD de la matriz identidad se puede simplificar como:\n","\n","$$I_n=UV^{T}$$\n","\n","Recordando el teorema $AA^{-1}=I$ (el orden no importa al ser matrices ortogonales), esto significa que las matrices $U, V^T$ deben ser inversas una de la otra, y al ser ortogonales se cumple que $A^{-1}=A^{T}$, por tanto\n","\n","$$U^{-1}=V^{T}$$\n","\n","esto significa entonces que $U=V$, esto permite simplificar mas la descomposicion SVD de la matriz identidad como:\n","\n","$$I_n=UU^{T}$$\n","\n","Ya que U es una matriz ortogonal, y del algebra lineal, hay infinitas matrices ortogonales ya que estas representan transformaciones como reflexiones y rotaciones en el espacio, y hay infinitas formas de rotar y reflectar. Por lo cual  hay infinitas formas de escribir $I_n=U\\Sigma V^{T}$ siendo $U$ una matriz ortogonal.\n","\n","Sabiendo que $V$ es una matriz ortogonal, se puede escribir la definicion de descomposicion SVD como\n","\n","$$AV=UΣ$$\n","\n","Escribiendo esto como componentes\n","\n","$$Av_i=\\sigma_i u_i \\tag{1}$$\n","\n","En otras palabras, la forma de escoger la matriz $V_r$ es verificando que se cumpla la condicion de la ecuacion (1), ya que, analizando esta ecuacion, la matriz $V_r$ correcta es aquella que al multiplicarla por la matriz original $A$, el resultado es una matriz cuyas columnas son las columnas $u_i$ de la matriz $U$, escaladas por el respectivo valor singular de la matriz $A$\n","\n","Respecto a los autovectores con autovalores igual a 0, de la descomposicion SVD, si un valor singular es cero, al ser la raiz de los autovalores, el autovalor correspondiente de $A^{*}A$ (o $AA^{*}$) tambien es cero.\n","\n","Sabiendo que los autovalores tambien representan la magnitud de una transformacion, los autovalores que correspoden a 0 nos dicen cuales \"dimensiones\", \"direcciones\" o \"vectores\" son \"comprimidos\" a 0, o nulificados por la matriz, ademas del algebra lineal, sabemos que si un autovalor es cero, esto significa que los infinitos autovectores asociados a este autovalor estan en el espacio nulo de $A^{*}A$ (o $AA^{*}$), y de las propiedades de los espacios vectoriales, el espacio nulo de $A^{*}A$ es igual al de $A$. Por lo que un autovalor igual a 0 nos dice que hay, al menos, un elemento en el espacio nulo de $A$, lo que lo hace mas grande, y por tanto distinto del espacio trivial de $A$, esto significa que la matriz no es invertible o singular.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ixdhG7uBAPMf"}}]}